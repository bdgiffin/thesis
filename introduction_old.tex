\chapter{Introduction}
%(An introductory description of the problem that is being addressed, which the presented research intends to resolve. The problem need not be described in explicit detail (i.e. we need not explain the mathematical aspects of solid mechanics in its totality), but it should address the locking problem to a sufficient extent, making it clear to the reader what the fundamental problem is, and why it is so difficult to address. Do not repeat the abstract; rather, build upon what was already said, but in more explicit terms.)

For every physical model, there exist discrepancies to be found with it; in the infamous words of Box: ``All models are wrong...but some are useful,'' a statement which certainly holds true in the context of modern computational solid mechanics. The field has evolved substantially since its early beginnings in the 1950s, developing into a mature area of research which encompasses more traditional engineering practices, as well as aspects of data and computer science, and even newly developed areas of mathematics.

Today, the early approximation methods (finite elements, in particular) have been extended for applications in modeling complex physical processes and engineered systems, but as a consequence, there has been a proliferation of different modeling techniques to accomodate these particular applications. To a large extent, such developments have succeeded in solving a few very specific problems relevant to the engineering community, but the accompanying explosion in model complexity has placed an undue burden upon engineering analysts, who are unhappily faced with the prospect of first: selecting a modeling method from the vast number that currently exist, and second: negotiating the many nuances and difficulties inherrent to the chosen methodology.

But despite the many recent advancements in techniques for modeling difficult problems such as contact, pervasive fracture, fluid-structure interaction, and so forth, seemingly limited progress has been made in the arenas of model discretization, and ``robustness'' in the face of arbitrary discretizations. These issues account for much of the disuse and distrust of more complex numerical models by the engineering community at large, for a single primary reason: model generation is stymied by rather severe restrictions on the discretization approaches in common usage, owing to the fact that the accuracy of the associated numerical models depends strongly upon the ``quality'' of the resulting discretization. In other words, model accuracy is too often the product of the chosen discretization.

This fact was identified fairly early on in the development of the traditional finite element method, giving rise to the notion of ``locking'' as a general phenomenon which is characterized by a loss of solution accuracy and/or convergence for some limiting value of a problem parameter. One of the most commonly discussed and addressed forms of locking in computational solid mechanics is the issue of ``volumetric locking,'' wherein a model attempting to represent a nearly incompressible material will suffer from a marked loss of accuracy. For an elastic material model, the parameter dependency in question relates to the Poisson's ratio. Other forms of locking may include ``shear locking,'' ``membrane locking,'' or ``trapezoidal locking,'' nearly all of which are a consequence of a poor choice of model discretization, particularly with regard to relatively thin beam- or plate-like geometries.

In response to these problems, various approaches were proposed as a means of handling different forms of locking, but they were altogether encumbered by still severe restrictions on element geometry. Consequently, traditional beam and shell element models are still commonly used by analysts in an effort to avoid these issues, though even structural elements are not immune to the effects of locking, and suffer from a host of their own (albeit related) problems.

Over the past few decades, there has been somewhat slow progress in the pursuit of so-called ``locking-free'' formulations, yet most of these only address one aspect of the locking problem (typically volumetric locking), and not the broad range of issues suggested by the terminology. Nonetheless, the methods which appear to have the most success almost invariably attempt to address the locking problem by respecting the discretization and compatibility at element interfaces only weakly (i.e. non-conforming and Discontinuous Galerkin methods).

As a consequence, Discontinuous Galerkin methods have attracted the attention of researchers in the field of numerical methods development for this very reason. However, the DG approaches have not obviated the usage of the canonical FEM and related methodologies for a number of reasons. One commonly cited reason relates to the fact that DG methods can become sensitive to the selection of certain penalty parameters used to weakly enforce inter-element continuity and boundary conditions, thereby imposing a rather arbitrary choice upon engineering analysts.

Nonetheless, the general consensus amongst those pursuing the development of truly ``robust'' numerical methods (those which perform well regardless of the specific choice of discretization) is that there is a need for abstraction away from the kinds of discretizations used to represent the approximate solution of a PDE on a given problem domain. In particular, certain forms of discretization may be convenient from a geometric perspective in the sense that they are easy to generate, but they may not result in a suitable approximation space for the given problem at hand.

These thoughts have initiated investigations into the element-free Galerkin (EFG) methodologies, on account of their apparent discretization independence. But what the EFG methods make up for in eliminating a dependence upon a structured partition of the domain, they lose on a number of other crucial considerations: namely, the handling of boundary conditions, and the numerical evaluation of integrals. These shortcomings notwithstanding, the EFG methods have crucially recognized the importance of constructing an approximation basis which is relatively unbiased by the particular discretization of the domain.

Such considerations led to the development of methods which attempted to accomodate the inherrent arbitrariness in the discretization. In some cases this resulted in various attempts to smooth out certain aspects of the approximation through some form of non-local regularization. These techniques have generally suffered from issues of numerical stability, and typically nullify most of the efficiency otherwise found in the regular finite elements which possess sparse and banded stiffness matricies.

Then there are the many polygonal and polyhedral finite element formulations, which some authors boast are entirely compatible with traditional finite elements, in that their basis functions on element boundaries are in agreement with the Lagrange interpolating polynomials. Problematically, however (and perhaps owing to the aforementioned reasons), these elements suffer from all of the same issues as ordinary finite elements with regard to their accuracy and robustness in the face of element distortion. Several papers on the subject demonstrate convergence of such methods for relatively simple problems, and using fairly regular polygonal or polyhedral meshes, but few of these investigate solution robustness across a broad range of possible problems on general polytopal meshes.

These concerns were ultimately the main motivation behind the method of incompatible modes, originally proposed by Ed Wilson, and later formalized by Simo et. al., among others.

\section{Outline}

\textbf{Guiding principle:} the introduction should not contain mathematical jargon or equations -- nearly everything should be described in words!!!!

\begin{itemize}
	\item Address the context/scope of the problems that we would like to solve using the finite element method: Lagrangian solid mechanics, finite deformations, arbitrary material models.
	\item Discuss some of the history behind the finite element method, and explain why it has persisted as a methodology for as long as it has.
	\item Polyhedral methods should try to mimic the core aspects of finite element methods (compact support, discrete representation of geometry for the sake of integration, resolving contact, etc.)
	\item Goal is to construct basis functions which possess compact support over the problem domain
	\item Primary motivation is to avoid the issues commonly encountered with standard discretizations: i.e. degraded accuracy on poorly meshed geometries.
	\item Discuss other polyhedral methods which exist in the literature
	\begin{itemize}
		\item Virtual element methods: consider projection of polynomial fields onto lower-dimensional polytopes
		\item Variable element topology finite element method: very similar in nature to the VEM, subject to somewhat stronger constraints on boundary conformity
		\item Generalized barycentric coordinates: considers various means of computing analytic shape functions defined point-wise over a polytopal element domain
		\item Smoothed finite element methods: consider smoothing domains which overlap between adjacent elements, and smooth strain field within these smoothing domains
		\item Classical partitioned element method (2012): effectively a weak galerkin type of approach on a locally subdivided element domain
	\end{itemize}
	\item Assess the aforementioned methods via a categorization into: methods that use polynomial projections (non-conforming/low-dimensional spaces), methods that use exact representations of analytic shape functions, and methods that use element-level discretization techniques
	\item The fundamental motivation behind finite elements was to make the element-level calculations be SIMPLE and straightforward -- predicated on the notion that local approximations within elements are reasonably accurate -- capture local solution behavior well
	\item Problem arises when elements become distorted, used in contexts where they yield poor local approximations to the true solution
\end{itemize}

\section{Mathematical Characterization of Solution Accuracy and Robustness}

\subsection{Literature on the Subject of Locking}

Babuska and Suri introduce the fundamental concept and rigorous mathematical definition of locking in \cite{Babuska&Suri:92:1}, and later consider applictions of these ideas for elasticity problems in \cite{Babuska&Suri:92:2}. Suri investigated the effectiveness of $h$- vs. $p$-refinement in the pursuit of overcoming certain locking phenomena in \cite{Suri:91}, concluding that, in particular, the issues of volumetric locking may be overcome using triangular discretizations with $p \geq 4$, but quadrilateral elements will nonetheless succumb to volumetric locking regardless of the chosen order of $p$.

Lee and Bathe investigated the effects of element distortion on the approximation power of isoparametric elements in \cite{Lee&Bathe:93}. It wasn't until Rajdendran in \cite{Rajendran:10} discovered that a modification of the trial and test function spaces could be made in order to recover solution accuracy for poorly distorted isoparametric elements.

\section{An Assessment of Various Approximation Methods}
%
A detailed discussion of various approximation schemes in common usage, and an evaluation of their performance in the context of non-linear solid mechanics.
\subsection{Continuous Galerkin Methods and the FEM}
\subsubsection{Structural Finite Elements}

\subsection{Discontinuous Galerkin Methods}

\subsection{Mesh Free Methods}

\subsection{Isogeometric Methods}

\subsection{Polytopal Element Methods}
\subsubsection{The Weak Galerkin Method}
\subsubsection{The Virtual Element Method}
\subsubsection{The Partitioned Element Method}

\section{Recent Advances in Domain Discretization}
%
An overview of various approaches to the problem of discretizing a solid domain for the purposes of obtaining a computational mesh amenable to a particular approximation scheme.
\subsection{Discretizations Using Regular Shapes}

\subsection{Discretizations with Arbitrary Polytopes}
\subsubsection{Voronoi Diagrams}
\subsubsection{Cut Cell Methods}

\subsection{Assessments of Mesh Quality}

\section{The Proposed Polytopal Element Framework}

(Explain the scope of your work, how this serves as a novel and innovative contribution that addresses the problem, what will and will not be addressed by this approach, and where the introductory material ("old stuff") ends and your contribution ("new stuff") begins.)

(Provide a coarse outline, guiding the reader to what lies ahead.)
