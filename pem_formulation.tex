\chapter{Partitioned Element Methods} \label{ch:pem}
%
This chapter defines a general class of polytopal element formulations referred to as partitioned element methods (PEM). The essential characteristics and mathematical requirements placed upon these methods are formally stated, giving rise to a family of different approaches, for which some formal investigations are conducted. Several specific formulations are summarized in detail, and a number of existing methods are herein classified as partitioned element methods.

\section{Overview}

		% goal is to construct shape functions on arbitrary polytopes
		% want efficient and stable quadrature rules
		% depart from the idea of shape functions defined pointwise
		% invoke idea behind FE approximation spaces: use discretization
		% solve local approximation problem to define SFs
		% enforce constraints to attain reproducibility & consistency

A partitioned element method is a finite element-like method which approaches the task of constructing shape functions on an arbitrary element domain by partitioning the element into simpler sub-domains (quadrature cells), and establishing a local approximation space defined on this partition. Optimal shape functions which minimize a chosen objective functional are selected from this approximation space, while respecting a set of imposed constraints.

The rationale behind PEM stems from the idea that it is generally easier to define shape functions which preserve desirable characteristics over arbitrary polytopal domains if the shape functions are defined in a piece-wise polynomial fashion over simpler sub-domains.

Partitioned element methods encompass the special case where the elements consist of a single sub-domain, henceforth referred to as single-cell methods, which are roughly equivalent to a VEM or VETFEM-like approach. Such methods typically require additional mesh regularity requirements to obtain favorable results; they are not particularly robust when applied to arbitrary polyhedral meshes (namely those generated by B-rep intersection), as they perform poorly if the element's geometry is sufficiently complicated.

At a minimum, the partitioned element method must satisfy 4 primary conditions:
\begin{itemize}
	\item \textbf{Reproducibility}: The shape functions (and their derivatives) must be capable of exactly reproducing any polynomial field up to a specified order $k$.
	\item \textbf{Compatibility}: The shape functions must maintain a sufficient degree of continuity at inter-element and intra-element interfaces.
	\item \textbf{Stability}: The local bilinear form defined on the element must satisfy the inf-sup condition.
	\item \textbf{Consistency}: The element must exactly integrate the weak form equations when the solution corresponds to a polynomial of maximal degree $k$.
\end{itemize}

In the following sections, an abstract framework for the PEM is established, and the above conditions are made precise in mathematical terms.

\section{An Abstract Partitioned Element Framework}
\subsection{The Element Partition}

	%consider an arbitrary element domain
	%discretize domain into conforming sub-domains: a partition
	%limitation: sub-domains must be polytopes
	%shape constraints imposed according to chosen approx. method

\begin{figure} [!ht]
	\centering
	\includegraphics[width = 4.0in]{figures/partition.png}
	\caption{A representative domain $\Omega \subset \mathbb{R}^2$, and it's corresponding partition into verticies, segments, and facets.}
	\label{fig:partitioned_element}
\end{figure}

\begin{itemize}
	\item Provide a figure of an element with partitioned geometry
	\item Define partitioned geometry terms (cells, facets, segments, verticies, etc.), perhaps even give a table of definitions, all referring back to the main figure(s)
	\item 
\end{itemize}

\subsection{Partition-Based Approximation Spaces}

		%define SFs as FE-like piece-wise polynomials on the partition
		%try to minimize number of basis functions for efficiency
		\subsubsection*{FE basis}
			%unknowns stored at verticies only (efficient)
			%easy generalization to high order
			%limited to canonical shapes (tris/tets, quads/hexas)
			%quadrature rules much simpler (may use high order)
			%equivalent to Joe Bishop's approach (w/ Laplace SFs)
			%less sensitive to conditioning problems
		\subsubsection*{WG basis}
			%unknowns stored on cells and edges
			%generalization to high order more expensive
			%Rashid & Sadri 2012 approach (low order)
			%may suffer from conditioning issues at high order
		\subsubsection*{DG basis}
			%unknowns stored on cells
			%easy generalization to high order
			%New/current approach
			%may suffer from conditioning issues at high order
		\subsubsection*{VE basis}
			%unknowns stored at verticies only (efficient)
			%high order generalization effected via serendipity SFs
			%generalizes to arbitrary polytopes
			%New/speculated approach
			%less sensitive to conditioning problems

Traditional approximation methods typically consider the independent specification of two principal transformations: an interpolation scheme, which is necessary to represent field variables according to known point-values; and a quadrature rule, for the purposes of integrating such fields over the domain on which they are defined.

In mathematical terms, an interpolant $\varphi$ is a linear operator which maps vectors $\mathbf{u} \in \mathbb{R}^k$ containing point-wise data regarding a field into scalar functions $f \in V^k (\Omega)$, i.e.
\begin{equation}
  \varphi \colon \mathbb{R}^k \mapsto V^k (\Omega)
\end{equation}
where $\mathbb{R}^k$ is a $k$-dimensional real space, and $V^k (\Omega)$ is a $k$-dimensional function space defined on $\Omega$.

By constrast, a quadrature rule $\Sigma$ is a linear operator which maps scalar functions $f \in V^k (\Omega)$ to vectors $\mathbf{q} \in \mathbb{R}^p$ identifying point-wise samples of $f$, i.e.
\begin{equation}
  \Sigma \colon V^k (\Omega) \mapsto \mathbb{R}^p
\end{equation}

The composition $\Sigma \circ \varphi$ of an interpolant $\varphi$ with a quadrature rule $\Sigma$ yields a linear operator
\begin{equation}
  \Sigma \circ \varphi \colon \mathbb{R}^k \mapsto \mathbb{R}^p
\end{equation}

\subsection{Partition-Based Quadrature Rules}
		%quadrature rules are defined/linked to the chosen partition
		%1-to-1 relation between partitioned cells and quadrature points
		%use Lassere integration to get weights of polytopal domains
		%employ low-order quadrature rules for the sake of efficiency
		%FE/simplicial discretization allows high-order composite rules
		
	\subsubsection*{Composite Midpoint Quadrature}
		
	\subsubsection*{Selective Modal Quadrature}
	
	Consider all functions $f \in L^2 (\Omega)$ represented over an arbitrary polytopal element domain $\Omega \subset \mathbb{R}^d$. Standard quadrature rules approximate the integral of $f$ over $\Omega$ as
	\begin{equation}
		\int_\Omega f \, dv \approx \sum_{q=1}^{N_{qp}} w_q f(\mathbf{x}_q).
	\end{equation}
	Consider an $L^2 (\Omega)$ polynomial projection operator $\Pi : L^2 \mapsto P^k$ which may be used to decompose $f = f_p + f_n$ into polynomial and non-polynomial parts:
	\begin{equation}
		f_p = \Pi f, \quad f_n = f - \Pi f = \pi f,
	\end{equation}
	where $\pi : L^2 \mapsto L^2 \backslash P^k$. Consequently, we observe that $\Pi f$ is $L^2$ orthogonal to any $\pi g$ for all $g \in L^2$, to the extent that
	\begin{equation}
		\int_{\Omega} (\Pi f) (g - \Pi g) \, dv = \langle \Pi f, g - \Pi g \rangle_{\Omega} = 0 \quad \forall f, \, g \in L^2.
	\end{equation}
	
	We propose a quadrature rule of the form:
	\begin{equation}
		\int_\Omega f \, dv \approx \int_\Omega f_p \, dv + \sum_{q=1}^{N_{qp}} w_q f_n(\mathbf{x}_q),
	\end{equation}
	where it is supposed that $\int_\Omega f_p \, dv$ may be computed exactly using the methodology proposed by Lasserre in \cite{Chin:15}. Further, if we wish to integrate the product $f g$ where $f, \, g \in H^1 (\Omega)$, we may write
	\begin{equation}
		\int_\Omega f g \, dv = \langle f, g \rangle_{\Omega} = \langle \Pi f + \pi f, \Pi g + \pi  g \rangle_{\Omega},
	\end{equation}
	which, by the linearity of the $L_2$ inner product, and by the orthogonality of $\Pi f$ and $\pi g$ (and of $\pi f$ and $\Pi g$), yields
	\begin{equation}
		\int_\Omega f g \, dv = \langle \Pi f, \Pi g \rangle_{\Omega} + \langle \pi f, \pi g \rangle_{\Omega},
	\end{equation}
	and thus
	\begin{equation}
		\int_\Omega f g \, dv \approx \int_\Omega f_p g_p \, dv + \sum_{q=1}^{N_{qp}} w_q f_n(\mathbf{x}_q) g_n(\mathbf{x}_q).
	\end{equation}
	This is effectively equivalent to integrating the product of all low-order polynomials exactly, while integrating the product of all non-polynomial ``remainders'' only approximately, using a quadrature rule.
	
	If we are only given point evaluations of a function $f$ at $\left\{ \mathbf{x}_q \right\}_{q=1}^{N_{qp}}$, then we must construct a low-order polynomial projection operator by considering the least-squares problem:
	\begin{equation}
		\min_{f_p \in P^k (\Omega)} \frac{1}{2} || f_p - f ||^2_\Omega,
	\end{equation}
	where $|| f ||_\Omega = \sqrt{\langle f, f \rangle_\Omega}$ is deliberately approximated using the element's quadrature rule:
	\begin{equation}
		\langle f, f \rangle_\Omega \approx \sum_{q=1}^{N_{qp}} w_q \left[ f(\mathbf{x}_q) \right]^2.
		\label{eq:L2projection}
	\end{equation}
	For a given polynomial basis $\left\{ z_a \right\}_{a=1}^{K}$ which spans $P^k (\Omega)$, we may write
	\begin{equation}
		f_p (\mathbf{x}) = \sum_{a=1}^{K} z_a (\mathbf{x}) c_a = \mathbf{z}^T (\mathbf{x}) \, \mathbf{c},
	\end{equation}
	and the solution to (\ref{eq:L2projection}) satisfies
	\begin{equation}
		\sum_{a=1}^{K} \sum_{q=1}^{N_{qp}} w_q z_b (\mathbf{x}_q) z_a (\mathbf{x}_q) c_a =
		\sum_{q=1}^{N_{qp}} w_q z_b (\mathbf{x}_q) f(\mathbf{x}_q) \quad \forall b = 1, \, \ldots, \, K,
	\end{equation}
	which may be written in matrix form as $\mathbf{Z}^T \mathbf{W} \mathbf{Z} \mathbf{c} = \mathbf{Z}^T \mathbf{W} \mathbf{f}$, where we denote $f_i = f(\mathbf{x}_i)$, $W_{ii} = w_i, \, W_{ij} = 0 \, \forall i \neq j$, and $Z_{ij} = z_j (\mathbf{x}_i)$. The discrete polynomial projection operator $\mathbf{\Pi} : \mathbb{R}^{N_{qp}} \mapsto \mathbb{R}^K$ is computed as $\boldsymbol{\Pi} = (\mathbf{Z}^T \mathbf{W} \mathbf{Z})^{-1} \mathbf{Z}^T \mathbf{W}$, and the complement operator $\boldsymbol{\pi} : \mathbb{R}^{N_{qp}} \mapsto \mathbb{R}^{N_{qp}}$ is $\boldsymbol{\pi} = \mathbf{1}_{N_{qp}} - \boldsymbol{\Pi}^\dagger \boldsymbol{\Pi}$. Consequently,
	\begin{equation}
		\langle \Pi f, \Pi g \rangle_{\Omega} = \langle \mathbf{z}^T \boldsymbol{\Pi} \mathbf{f}, \mathbf{z}^T \boldsymbol{\Pi} \mathbf{g} \rangle_{\Omega} = \mathbf{f}^T \left[ \boldsymbol{\Pi}^T \left( \int_{\Omega} \mathbf{z} \otimes \mathbf{z} \, dv \right) \boldsymbol{\Pi} \right] \mathbf{g} = \mathbf{f}^T \mathbf{W}_p \mathbf{g},
	\end{equation}
	\begin{equation}
		\langle \pi f, \pi g \rangle_{\Omega} \approx \sum_{q=1}^{N_{qp}} w_q f_n(\mathbf{x}_q) g_n(\mathbf{x}_q) = \mathbf{f}^T \left[ \boldsymbol{\pi}^T \mathbf{W} \boldsymbol{\pi} \right] \mathbf{g} = \mathbf{f}^T \mathbf{W}_n \mathbf{g},
	\end{equation}
	\begin{equation}
		\int_\Omega f g \, dv \approx \mathbf{f}^T (\mathbf{W}_p + \mathbf{W}_n) \mathbf{g} = \mathbf{f}^T \mathbf{M} \mathbf{g} = \sum_{q = 1}^{N_{qp}} \sum_{p = 1}^{N_{qp}} M (\mathbf{x}_q,\mathbf{x}_p) \, f (\mathbf{x}_q) \, g (\mathbf{x}_p).
	\end{equation}
	
	We shall refer to this form of integration as \textit{selective modal quadrature}, in that particular low-order polynomial modes are integrated exactly, and any higher modes are approximated using the element's quadrature rules. The advantage of modal quadrature is that we may exactly integrate any terms which directly impact quadrature consistency, and hence, virtually any stable quadrature may be used to integrate the higher-order part.
	
	Rather than storing the independent quadrature weights $w_q = w (\mathbf{x}_q)$, selective modal quadrature requires the storage of a generalized quadrature weighting matrix $M (\mathbf{x}_q,\mathbf{x}_p)$. Alternatively, for the sake of efficiency, if the function $g$ is known a priori (e.g. if $g$ is a test function for a weighted residual method), then we need only store the ``augmented'' test function values:
	\begin{equation}
		\tilde{g} (\mathbf{x}_q) = \sum_{p = 1}^{N_{qp}} \frac{M(\mathbf{x}_q,\mathbf{x}_p)}{w_q} \, g (\mathbf{x}_p),
	\end{equation}		
	and all integrals involving $f$ and $g$ may be carried out via
	\begin{equation}
		\int_\Omega f g \, dv \approx \sum_{q = 1}^{N_{qp}} \, w_q \, \tilde{g} (\mathbf{x}_q) \, f (\mathbf{x}_q),
	\end{equation}
	which is effectively equivalent to a gradient correction scheme, similar to the method proposed in \cite{Talischi:15}.

\subsection{Selection of an Appropriate Objective Functional}

	%PEM BOUNDARY VALUE PROBLEMS
		%setup: define a space of approximating functions over the element (basis)
		%goal:  select shape functions from this basis that are "optimal"
			%trial functions should reproduce polynomials as best they can
			%test functions should be close to trial functions (for stability)
			%test functions should satisfy compatibility requirements weakly
			%test functions should satisfy quad. consistency requirements against polys.
		%must propose a positive-definite functional to minimize on E
		%must enforce constraints on minimization
			%consistency enforced via Lagrange multipliers
		%develop a resulting system of equations
		%condense out all internal dofs in terms of element nodal values
		%allows for the inclusion of optional enhanced dofs, if needed
		%want SFs to be free of pathologies
		%Laplace shape functions
			%Joe Bishop's approach
			%Rashid & Sadri 2012 approach
		%Least-squares penalty method
			%necessary to stabilize WG/DG approaches
		%Other methods
			%many things to explore in this regard...
			%biharmonic? (for higher-order completeness? C^1 hard)

Once we have specified a given approximation space of functions, our goal is then to select the function from this space which best represents the nodal data that we are attempting to interpolate over the element. The essential question is this: by what metric should we objectively assess the appropriateness of a given approximating function?

\subsection{Construction of Element Appoximants}

\section{Essential Requirements of the PEM}

\subsection{Reproducibility}

Fundamentally, the approximation power of the PEM depends directly upon the degree of completeness of the underlying approximation space. In particular, the finite-dimensional trial solution space $\mathcal{S}^h$ should contain as a subspace $\mathbb{P}_k \subset \mathcal{S}^h$ for some $k \geq 0$, where $\mathbb{P}_k$ denotes the subspace of polynomial functions with maximal degree $k$. This guarantees that the PEM approximation space will be capable of exactly reproducing any polynomial function up to some specified order.

	%driven by completeness requirements
	%handled by BVP/functional specification
	%alternatively enforced via constraints

\subsubsection{Requirements of the Approximation Space}
\subsection{Compatibility}

	%driven by the generalized patch test
	%handled by constraints on approximation spaces/BVP

Compatibility, in an abstract sense, refers to the property of there being a unique displacement field (up to rigid translations) which gives rise to a particular strain field. This condition is satisfied directly if the displacement field is continuous (i.e. if the displacement field $\mathbf{u} \in C^0$). This condition is met if standard ``compatible'' finite elements are utilized, whose trial solution space $\mathcal{S}^h$ is a subset of $C^0$, namely $\mathcal{S}^h \subset H^1 \subset C^0$.

Failure to satisfy compatibility in a strong sense (i.e. point-wise) does not altogether preclude the convergence of a given approximation method. Some authors have proposed that satisfaction of the Irons patch test is sufficient for convergence. It was later shown, however, that the Irons patch test is neither sufficient, nor necessary for convergence. Most notably, Stummel has proposed in \cite{Stummel:79} the necessary and sufficient conditions for convergence of a non-conforming finite element method. These conditions include approximability, and passage of a so-called ``generalized patch test,'' which asserts:

\textit{For a given patch $S \subset \overline{\Omega}$ and an approximating sequence of functions $u^h \in H^k (\Omega^h)$: for every $\mathbf{x} \in S$ there exists an open neighborhood $O$ in $\mathbb{R}^d$ such that}
\begin{equation}
  \lim_{h \rightarrow 0} \sum_{\Omega_e \in \mathcal{P}_h} \int_{\partial \Omega_e} \varphi \, \partial^\alpha u^h|_{\Omega_e} \mathbf{n} \, da = \mathbf{0}
\end{equation}
\textit{for all test functions $\varphi \in C^{\infty}_0 (O)$, and $| \alpha | \leq k-1$.}

Moreover, Stummel provides in \cite{Stummel:80} a number of counter-examples of elements which pass the patch tests of Irons and Strang, but which yield approximations which do not converge to the exact solution.

\subsubsection{Weak Enforcement of Continuity}
\subsection{Stability}

		%driven by the inf-sup conditions
		%handled via sufficient quadrature arrangement

\subsubsection{Restrictions on the Element Partition}
\subsection{Variational Consistency}
\subsubsection{Weak Enforcement of Consistency}

		%driven by Galerkin exactness
		%enforced by quadrature accuracy
		%alternatively via lagrange multiplier constraint

Consider the variational formulation for the model solid mechanics problem:

Find $\mathbf{u} \in \mathcal{S} = \left\{ \mathbf{u} \in H^1(\Omega), \mathbf{u} = \bar{\mathbf{u}} \, \, \forall \mathbf{x} \in \Gamma_u \right\}$ such that
\begin{equation}
  \int_\Omega (T_{ij,j} + \rho b_i) v_i \, dv = 0
\end{equation}
for all $\mathbf{v} \in \mathcal{V} = \left\{ \mathbf{v} \in H^1(\Omega), \mathbf{v} = \mathbf{0} \, \, \forall \mathbf{x} \in \Gamma_u \right\}$. Alternatively,
\begin{equation}
  \int_\Omega T_{ij} v_{i,j} \, dv - \int_\Omega \rho b_i v_i \, dv = \int_{\Gamma_t} \bar{t}_i v_i \, da.
\end{equation}
Now, let us contemplate a particular representation $v^h_i = \sum_{a=1}^N \varphi_a v_{ia}$, where $\mathbf{v}^h \in \mathcal{V}^h$ and $\mathcal{V}^h \subset \mathcal{V}$, resulting in
\begin{equation}
  \int_\Omega T_{ij} \varphi_{a,j} \, dv - \int_\Omega \rho b_i \varphi_a \, dv = \int_{\Gamma_t} \bar{t}_i \varphi_a \, da \quad \forall i, a.
\end{equation}
The above expression should be satisfied \textit{exactly} when the exact solution $\mathbf{u}$ lies within the finite dimensional approximation space $\mathcal{S}^h \subset \mathcal{S}$. Given an exact solution $\bar{T}_{ij}$ arising from some prescribed $\bar{t}_i = \bar{T}_{ij} n_j$ and $\rho b_i = - \bar{T}_{ij,j}$, we may express
\begin{equation}
  \int_\Omega \bar{T}_{ij} \varphi_{a,j} \, dv + \int_\Omega \bar{T}_{ij,j} \varphi_a \, dv = \int_{\partial \Omega} \bar{T}_{ij} n_j \varphi_a \, da \quad \forall i, a.
\end{equation}
If $\bar{T}_{ij}$ can be written as a polynomial expansion, i.e.
\begin{equation}
  \bar{T}_{ij} (\mathbf{x}) = \sum_{|\alpha| = 0}^k \bar{T}_{ij\alpha} \mathbf{x}^\alpha,
\end{equation}
then the $\alpha$-th order variational consistency requirement asserts:
\begin{equation}
  \int_\Omega \mathbf{x}^{\alpha} \varphi_{a,i} \, dv + \int_\Omega \mathbf{x}^{\alpha}_{,i} \varphi_a \, dv = \int_{\partial \Omega} \mathbf{x}^{\alpha} n_i \varphi_a \, da \quad \forall i, a.
\end{equation}
This degree of consistency is required if the bi-linear form $B(u,v)$ on $\mathcal{S}$ and $\mathcal{V}$ is to determine uniqueness of any exact polynomial solutions contained within $\mathcal{S}$. Moreover, the above expression guarantees that any solution may be reasonably well approximated by low-order polynomials in the locality of the selected domain $\Omega$.

Consequently, we may consider an application of the above consistency requirements to the entire problem domain $\Omega$, or -- more practically -- we may enforce consistency up to the desired order on each element domain $\Omega_e$. The element-local $\alpha$-th order consistency equations follow:
\begin{equation}
  \int_{\Omega_e} \mathbf{x}^{\alpha} \varphi_{a,i} \, dv + \int_{\Omega_e} \mathbf{x}^{\alpha}_{,i} \varphi_a \, dv = \int_{\partial \Omega_e} \mathbf{x}^{\alpha} n_i \varphi_a \, da \quad \forall i, a.
  \label{eq:consistency}
\end{equation}

It should be emphasized that the consistency equations set forth are conditions which apply only to the test functions $\varphi_a \in \mathcal{V}^h$, and not to the trial functions $\phi_a \in \mathcal{S}^h$. The trial solution space must, however, be capable of reproducing all polynomial solutions (and their derivatives) up to some corresponding order $k$, such that $\mathbb{P}_k \subset \mathcal{S}^h$.

In most practical situations, it may not be possible to evaluate the integral expressions exactly. Instead, numerical quadrature rules must be defined, both on the element's interior, and on its boundary, such that
\begin{equation}
  \int_{\Omega_e} f(\mathbf{x}) dv \approx \sum_{q=1}^{N_q} w_q f(\mathbf{x}_q),
\end{equation}
\begin{equation}
  \int_{\partial \Omega_e} f(\mathbf{x}) da \approx \sum_{b=1}^{N_b} w_b f(\mathbf{x}_b).
\end{equation}
This yields yet another form of consistency, henceforth referred to as ``quadrature consistency,'' expressed as:
\begin{equation}
  \sum_{q=1}^{N_q} w_q \left[ \mathbf{x}_q^{\alpha} \varphi^{(q)}_{a,i} + \mathbf{x}^{\alpha}_{q,i} \varphi^{(q)}_a \right] = \sum_{b=1}^{N_b} w_b \mathbf{x}_b^{\alpha} n^{(b)}_i \varphi^{(b)}_a \quad \forall i, a.
  \label{eq:quadrature_consistency}
\end{equation}
Moving forward in our developments, quadrature consistency will be the only form of consistency of practical interest, as it appropriately reflects the discrete data quantities at our disposal.

A brief remark should be made regarding the lack of equivalence between the exact evaluation of consistency in equation (\ref{eq:consistency}) and its numerical approximation in equation (\ref{eq:quadrature_consistency}). In general, we cannot claim that satisfaction of one guarantees the other. There is only one occasion when we may say that (\ref{eq:quadrature_consistency}) holds if and only if (\ref{eq:consistency}) is satisfied, which occurs only when sufficiently accurate quadrature rules are used on the element and its boundary. In the vast majority of situations, however, this is an impractical constraint, as the construction of high-order quadrature rules on arbitrary polyhedra (though possible) proves to be somewhat computationally intensive (see the literature by Sukumar, etc.). Moreover, without a precise representation of the test functions over the element domain, it becomes infeasible to consider an exact integration of such functions.

\subsection{Numerical Quadrature Consistency}

Beyond consistency with the weak form for a specified subspace of polynomial functions used to represent the solution, we also require that the numerical quadrature scheme utilized be sufficiently accurate to the extent that: Galerkin exactness is satisfied for certain classes of solutions, and that the quadrature error has a bound which is of a lower order than that of the approximation error.

\subsubsection{Bubnov-Galerkin and Petrov-Galerkin Approaches}

\section{Specific Formulations}

\subsection{The Continuous-Galerkin PEM}

	% Harmonic SFs with an FE basis (Joe Bishop's approach)

\subsection{The Weak-Galerkin PEM}

	% Stabilized harmonic SFs with WG basis (Rashid & Sadri approach)

\subsection{The Discontinuous-Galerkin PEM}

	% C^k penalty approximating SFs with DG basis (new method)
	
\subsection{PEM Based on Composite Virtual Elements}

	% Harmonic SFs with VE basis + stabilization (new method)

\section{Enhancements to Improve Solution Accuracy}

		%GENERAL RULE: enhancements should seek to increase completeness
			%witnessed in most incompatible modes formulations
			%only way to improve accuracy: increase order, locally
		%balance stability, consistency, compatibility, reproducibility
			%bubble function construction closely tied to other SFs
			%enhancements must be orthogonal to low-order terms
			%must satisfy compatibility weakly over whole boundary
		%element-wide high order enhancement functions
			%inexpensive way to improve polynomial completeness
			%may apply to boundary dofs, or internal dofs

\subsection{Partition-Based Enhancement Functions}
\subsection{Mixed PEM Discretizations}
